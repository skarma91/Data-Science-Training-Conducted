{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7226ed58",
   "metadata": {},
   "source": [
    "# NLP Basics\n",
    "\n",
    "In this notebook we shall discuss different preprocessing steps to apply on tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2a53f",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "We will use **nltk**. If nltk is not installed, you can install it by `pip install nltk` in anaconda prompt. Once nltk is installed do the following:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('stopwords')          # this will download the stopwords\n",
    "nltk.download('twitter_samples')    # this will download labelled twitter samples for sentiment analysis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96badfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:14:13.058357Z",
     "start_time": "2022-11-27T13:14:10.219712Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812f936",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4292c",
   "metadata": {},
   "source": [
    "The `twitter_samples` contains subsets of 5000 positive tweets and 5000 negative tweets, and a full set of 10000 tweets.\n",
    "We need to use 5000 positive and 5000 negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cba9a58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:17:07.097857Z",
     "start_time": "2022-11-27T13:17:03.729672Z"
    }
   },
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650bc7df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:18:49.435143Z",
     "start_time": "2022-11-27T13:18:49.423021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
       " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
       " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
       " '@97sides CONGRATS :)',\n",
       " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_positive_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6942c929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:18:58.575210Z",
     "start_time": "2022-11-27T13:18:58.565705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hopeless for tmr :(',\n",
       " \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\",\n",
       " '@Hegelbon That heart sliding into the waste basket. :(',\n",
       " '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
       " 'Dang starting next week I have \"work\" :(']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_negative_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10751a00",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af14643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:43:15.766988Z",
     "start_time": "2022-11-27T13:43:15.760169Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604b56ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:30:41.462112Z",
     "start_time": "2022-11-27T13:30:41.442129Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ffe1eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:30:58.311464Z",
     "start_time": "2022-11-27T13:30:58.302418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7248e040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:33:00.940795Z",
     "start_time": "2022-11-27T13:33:00.921353Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet = all_positive_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd2b480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:33:22.848210Z",
     "start_time": "2022-11-27T13:33:22.840242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'#', '', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0f15710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:50:28.683424Z",
     "start_time": "2022-11-27T13:50:28.668124Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"\n",
    "    This function process a tweet\n",
    "    input:\n",
    "        tweet: string -> a string containing tweet\n",
    "    output:\n",
    "        tweet_clean: string -> a list of words containing processed tweets\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # remove the hashtags -> remove the # sign from the word\n",
    "    tweet = re.sub(r'#','',tweet)\n",
    "    \n",
    "    # remove the stock market tickers like $AMAZON\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+','', tweet)\n",
    "    \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove numbers\n",
    "    tweet = re.sub(\"\\d+\", \"\", tweet)\n",
    "    \n",
    "    # tokenize the tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    \n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and   # removes stopwords\n",
    "            word not in string.punctuation):    # removes punctuations\n",
    "            stem_word = stemmer.stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "            \n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5077949b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:50:29.865029Z",
     "start_time": "2022-11-27T13:50:29.839899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n",
      "['hey', 'jame', 'odd', ':/', 'pleas', 'call', 'contact', 'centr', 'abl', 'assist', ':)', 'mani', 'thank']\n",
      "['listen', 'last', 'night', ':)', 'bleed', 'amaz', 'track', 'scotland']\n",
      "['congrat', ':)']\n",
      "['yeaaah', 'yipppi', 'accnt', 'verifi', 'rqst', 'succeed', 'got', 'blue', 'tick', 'mark', 'fb', 'profil', ':)', 'day']\n"
     ]
    }
   ],
   "source": [
    "for x in all_positive_tweets[:5]:\n",
    "    print(process_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea1f25e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T13:51:23.309116Z",
     "start_time": "2022-11-27T13:51:23.291353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hopeless', 'tmr', ':(']\n",
      "['everyth', 'kid', 'section', 'ikea', 'cute', 'shame', \"i'm\", 'nearli', 'month', ':(']\n",
      "['heart', 'slide', 'wast', 'basket', ':(']\n",
      "['“', 'hate', 'japanes', 'call', 'bani', ':(', ':(', '”']\n",
      "['dang', 'start', 'next', 'week', 'work', ':(']\n"
     ]
    }
   ],
   "source": [
    "for x in all_negative_tweets[:5]:\n",
    "    print(process_tweet(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f14bf02",
   "metadata": {},
   "source": [
    "## Generate vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd40f586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:21:11.630240Z",
     "start_time": "2022-11-27T14:21:11.620417Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [\"I love my country\", \"I hate EDM\", \"I love to do math\", \"I am very bad at history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17eb66ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:20:58.010012Z",
     "start_time": "2022-11-27T14:20:58.002195Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(corpus):\n",
    "    vocabulary = []\n",
    "    for x in corpus:\n",
    "        for word in process_tweet(x):\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9dce62ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:21:26.399505Z",
     "start_time": "2022-11-27T14:21:26.376185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'countri', 'hate', 'edm', 'math', 'bad', 'histori']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = create_vocabulary(corpus)\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6eda4ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:21:28.157138Z",
     "start_time": "2022-11-27T14:21:28.147062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6855c28",
   "metadata": {},
   "source": [
    "Let's create the vocabulary for our tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c10987fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:22:19.682617Z",
     "start_time": "2022-11-27T14:22:19.666150Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_corpus = all_positive_tweets + all_negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9be49b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:22:27.079657Z",
     "start_time": "2022-11-27T14:22:27.060485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89414410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:22:39.377047Z",
     "start_time": "2022-11-27T14:22:32.313767Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_vocab = create_vocabulary(tweet_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce9f04d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T14:22:44.983194Z",
     "start_time": "2022-11-27T14:22:44.963070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9905"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a712ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
